{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SL. No.  Incident ID              Caller   Location     Customer  \\\n",
      "0      177       684477           Surat Jcs    Gujarat    Haldirams   \n",
      "1      178       684476           LTT Coach     Mumbai    Haldirams   \n",
      "2      179       684475        Avadhesh Jha      Noida  Progressive   \n",
      "3      180       684470                 GVK  Hyderabad    Haldirams   \n",
      "4      181       684466  VJS Hinjawadi Pune       Pune    Haldirams   \n",
      "\n",
      "             Log Time    Status Classification      Category  Pr  ...  \\\n",
      "0 2024-02-29 23:34:43    Closed         Issues  Other Issues  P1  ...   \n",
      "1 2024-02-29 23:20:43    Closed         Issues  Other Issues  P2  ...   \n",
      "2 2024-02-29 23:20:04  Resolved         Issues  Other Issues  P3  ...   \n",
      "3 2024-02-29 21:31:29    Closed         Issues  Other Issues  P1  ...   \n",
      "4 2024-02-29 20:31:53   Pending         Issues     POS Issue  P1  ...   \n",
      "\n",
      "  Partner Incident Incident Start Partner Priority        Incident End  \\\n",
      "0              NaN            NaN                0 2024-03-02 17:15:07   \n",
      "1              NaN            NaN                0 2024-03-04 12:43:26   \n",
      "2              NaN            NaN                0 2024-03-08 13:19:24   \n",
      "3              NaN            NaN                0 2024-03-04 14:00:20   \n",
      "4              NaN            NaN                0                 NaT   \n",
      "\n",
      "  Vendor Solution                                           Solution  TTO  \\\n",
      "0             NaN                           Issue has been resolved.  1.0   \n",
      "1             NaN  Issue has been resolved. All cameras are worki...  1.0   \n",
      "2             NaN                           Issue has been resolved.  1.0   \n",
      "3             NaN               Issue resolved TO done successfully.  1.0   \n",
      "4             NaN                                                NaN  1.0   \n",
      "\n",
      "   TTR  Closure Code Resolve Time (24/7)  \n",
      "0  1.0      Resolved       1 d:17 h:41 m  \n",
      "1  1.0      Resolved       3 d:13 h:23 m  \n",
      "2  1.0      Resolved       7 d:13 h:59 m  \n",
      "3  1.0      Resolved       3 d:16 h:29 m  \n",
      "4  NaN           NaN                 NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# melbourne_data = pd.read_excel(\"PMS Dashboard of Medanta.xlsx\", sheet_name=\"Medanta Modified Daily Incident\") \n",
    "# melbourne_data.describe()\n",
    "\n",
    "# Provide the full path to the Excel file if it's not in the same directory as your script\n",
    "file_path = \"Haldiram.xlsx\"\n",
    "\n",
    "# Try to read the Excel file\n",
    "try:\n",
    "    data = pd.read_excel(file_path, sheet_name=\"Raw Data\")\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{file_path}' not found.\")\n",
    "except PermissionError:\n",
    "    print(f\"No permission to access the file '{file_path}'.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SL. No.', 'Incident ID', 'Caller', 'Location', 'Customer', 'Log Time',\n",
       "       'Status', 'Classification', 'Category', 'Pr', 'iority', 'Symptom',\n",
       "       'Workgroup', 'Analyst', 'Response', 'Escalated To', 'Partner Incident',\n",
       "       'Incident Start', 'Partner Priority', 'Incident End', 'Vendor Solution',\n",
       "       'Solution', 'TTO', 'TTR', 'Closure Code', 'Resolve Time (24/7)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditions\n",
    "condition_1 = data['Status'].isin(['Closed', 'Resolved'])\n",
    "condition_2 = data['Analyst'].isin(['Aman Singh', 'Annapurna Mishra', 'Dinesh Supare', 'Dubesh Pardhi', 'Gaurav Agutalewar', 'Hitendra Chacherkar', 'Mr Shubham Narendra Hadge', 'Rahul Kotian', 'Sakhtivel Sundaram', 'Swapnil Paunikar'])\n",
    "\n",
    "# Apply conditions\n",
    "data['P'] = np.where(condition_1 & condition_2, 1, '')\n",
    "\n",
    "# Convert 'R' column to numeric\n",
    "data['P'] = pd.to_numeric(data['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SL. No.  Incident ID              Caller   Location     Customer  \\\n",
      "0      177       684477           Surat Jcs    Gujarat    Haldirams   \n",
      "1      178       684476           LTT Coach     Mumbai    Haldirams   \n",
      "2      179       684475        Avadhesh Jha      Noida  Progressive   \n",
      "3      180       684470                 GVK  Hyderabad    Haldirams   \n",
      "4      181       684466  VJS Hinjawadi Pune       Pune    Haldirams   \n",
      "\n",
      "             Log Time    Status Classification      Category  Pr  ...  \\\n",
      "0 2024-02-29 23:34:43    Closed         Issues  Other Issues  P1  ...   \n",
      "1 2024-02-29 23:20:43    Closed         Issues  Other Issues  P2  ...   \n",
      "2 2024-02-29 23:20:04  Resolved         Issues  Other Issues  P3  ...   \n",
      "3 2024-02-29 21:31:29    Closed         Issues  Other Issues  P1  ...   \n",
      "4 2024-02-29 20:31:53   Pending         Issues     POS Issue  P1  ...   \n",
      "\n",
      "  Partner Priority        Incident End Vendor Solution  \\\n",
      "0                0 2024-03-02 17:15:07             NaN   \n",
      "1                0 2024-03-04 12:43:26             NaN   \n",
      "2                0 2024-03-08 13:19:24             NaN   \n",
      "3                0 2024-03-04 14:00:20             NaN   \n",
      "4                0                 NaT             NaN   \n",
      "\n",
      "                                            Solution  TTO  TTR  Closure Code  \\\n",
      "0                           Issue has been resolved.  1.0  1.0      Resolved   \n",
      "1  Issue has been resolved. All cameras are worki...  1.0  1.0      Resolved   \n",
      "2                           Issue has been resolved.  1.0  1.0      Resolved   \n",
      "3               Issue resolved TO done successfully.  1.0  1.0      Resolved   \n",
      "4                                                NaN  1.0  NaN           NaN   \n",
      "\n",
      "   Resolve Time (24/7)    P    C  \n",
      "0        1 d:17 h:41 m  1.0  1.0  \n",
      "1        3 d:13 h:23 m  1.0  1.0  \n",
      "2        7 d:13 h:59 m  1.0  1.0  \n",
      "3        3 d:16 h:29 m  1.0  1.0  \n",
      "4                  NaN  NaN  NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "data['Symptom'] = data['Symptom'].astype(str)\n",
    "\n",
    "# Define conditions\n",
    "contains_specific_words = data['Symptom'].str.contains('Install|Update|Config', case=False, na=False)\n",
    "only_numbers = data['Symptom'].str.match(r'^[0-9]*$')\n",
    "only_digits_or_symbol = data['Symptom'].str.match(r'^[\\d@#$%]*$')\n",
    "no_alphabetic_characters = ~data['Symptom'].str.contains(r'[a-zA-Z]')\n",
    "\n",
    "condition_1 = contains_specific_words | (only_numbers | only_digits_or_symbol | no_alphabetic_characters)\n",
    "\n",
    "\n",
    "condition_2 = data['Status'].isin(['Closed','Resolved'])\n",
    "condition_3 = data['Analyst'].isin(['Aman Singh', 'Annapurna Mishra', 'Dinesh Supare', 'Dubesh Pardhi', 'Gaurav Agutalewar', 'Hitendra Chacherkar', 'Mr Shubham Narendra Hadge', 'Rahul Kotian', 'Sakhtivel Sundaram', 'Swapnil Paunikar'])\n",
    "\n",
    "# Combine conditions using logical AND\n",
    "conditions = condition_1 & condition_2 & condition_3\n",
    "\n",
    "# Apply conditions\n",
    "data['C'] = np.where(conditions, 0, np.where(condition_2 & condition_3, 1, ''))\n",
    "\n",
    "\n",
    "# Convert 'R' column to numeric\n",
    "data['C'] = pd.to_numeric(data['C'])\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SL. No.  Incident ID              Caller   Location     Customer  \\\n",
      "0      177       684477           Surat Jcs    Gujarat    Haldirams   \n",
      "1      178       684476           LTT Coach     Mumbai    Haldirams   \n",
      "2      179       684475        Avadhesh Jha      Noida  Progressive   \n",
      "3      180       684470                 GVK  Hyderabad    Haldirams   \n",
      "4      181       684466  VJS Hinjawadi Pune       Pune    Haldirams   \n",
      "\n",
      "             Log Time    Status Classification      Category  Pr  ...  \\\n",
      "0 2024-02-29 23:34:43    Closed         Issues  Other Issues  P1  ...   \n",
      "1 2024-02-29 23:20:43    Closed         Issues  Other Issues  P2  ...   \n",
      "2 2024-02-29 23:20:04  Resolved         Issues  Other Issues  P3  ...   \n",
      "3 2024-02-29 21:31:29    Closed         Issues  Other Issues  P1  ...   \n",
      "4 2024-02-29 20:31:53   Pending         Issues     POS Issue  P1  ...   \n",
      "\n",
      "         Incident End Vendor Solution  \\\n",
      "0 2024-03-02 17:15:07             NaN   \n",
      "1 2024-03-04 12:43:26             NaN   \n",
      "2 2024-03-08 13:19:24             NaN   \n",
      "3 2024-03-04 14:00:20             NaN   \n",
      "4                 NaT             NaN   \n",
      "\n",
      "                                            Solution  TTO  TTR  Closure Code  \\\n",
      "0                           Issue has been resolved.  1.0  1.0      Resolved   \n",
      "1  Issue has been resolved. All cameras are worki...  1.0  1.0      Resolved   \n",
      "2                           Issue has been resolved.  1.0  1.0      Resolved   \n",
      "3               Issue resolved TO done successfully.  1.0  1.0      Resolved   \n",
      "4                                                NaN  1.0  NaN           NaN   \n",
      "\n",
      "   Resolve Time (24/7)    P    C    R  \n",
      "0        1 d:17 h:41 m  1.0  1.0  0.0  \n",
      "1        3 d:13 h:23 m  1.0  1.0  1.0  \n",
      "2        7 d:13 h:59 m  1.0  1.0  0.0  \n",
      "3        3 d:16 h:29 m  1.0  1.0  1.0  \n",
      "4                  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define conditions\n",
    "condition_1 = (len(data['Solution']) < 7) | (data['Solution'] == \"\") | (data['Solution'].str.lower() == 'issue has been resolved') | (data['Solution'].str.lower() == 'issue has been resolved.')\n",
    "# condition_1 = (len(data['Solution']) < 7) | (data['Solution'] == \"\") | data['Solution'].str.contains('issue has been resolved', case=False, na=False)\n",
    "condition_2 = data['Status'].isin(['Closed','Resolved'])\n",
    "condition_3 = data['Analyst'].isin(['Aman Singh', 'Annapurna Mishra', 'Dinesh Supare', 'Dubesh Pardhi', 'Gaurav Agutalewar', 'Hitendra Chacherkar', 'Mr Shubham Narendra Hadge', 'Rahul Kotian', 'Sakhtivel Sundaram', 'Swapnil Paunikar'])\n",
    "\n",
    "# Combine conditions using logical AND\n",
    "conditions = condition_1 & condition_2 & condition_3\n",
    "\n",
    "# Apply conditions\n",
    "data['R'] = np.where(conditions, 0, np.where(condition_2 & condition_3, 1, ''))\n",
    "\n",
    "# Convert 'R' column to numeric\n",
    "data['R'] = pd.to_numeric(data['R'])\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Analyst  Closed Tickets  AVG/Day  Resolved Tkt     SLA %  \\\n",
      "0          Gaurav Agutalewar             106      4.1         104.0  0.981132   \n",
      "1              Dubesh Pardhi              97      3.7          93.0  0.958763   \n",
      "2              Dinesh Supare              84      3.2          54.0  0.642857   \n",
      "3           Annapurna Mishra              83      3.2          77.0  0.927711   \n",
      "4        Hitendra Chacherkar              72      2.8          57.0  0.791667   \n",
      "5           Swapnil Paunikar              36      1.4          36.0  1.000000   \n",
      "6         Sakhtivel Sundaram              32      1.2          29.0  0.906250   \n",
      "7  Mr Shubham Narendra Hadge              21      0.8           9.0  0.428571   \n",
      "8                 Aman Singh              14      0.5          12.0  0.857143   \n",
      "9               Rahul Kotian              13      0.5           6.0  0.461538   \n",
      "\n",
      "        TQR  \n",
      "0  0.924528  \n",
      "1  0.773196  \n",
      "2  0.896825  \n",
      "3  0.654618  \n",
      "4  0.902778  \n",
      "5  0.981481  \n",
      "6  0.875000  \n",
      "7  0.936508  \n",
      "8  0.880952  \n",
      "9  0.846154  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply condition_2 to filter data\n",
    "filtered_data = data[condition_2]\n",
    "\n",
    "# Calculate count of tickets per analyst\n",
    "ticket_counts = filtered_data['Analyst'].value_counts().reset_index()\n",
    "ticket_counts.columns = ['Analyst', 'Closed Tickets']\n",
    "\n",
    "# Calculate average tickets per analyst (assuming 26 as divisor)\n",
    "ticket_counts['AVG/Day'] = (ticket_counts['Closed Tickets'] / 26).round(1).astype(float)\n",
    "\n",
    "# Assuming TTR represents Time to Resolution and is a boolean column\n",
    "# Filter data based on TTR condition\n",
    "filtered_data_TTR = data[data['TTR'] == True]\n",
    "\n",
    "# Calculate count of tickets per analyst where TTR condition is met\n",
    "SLA_Met = filtered_data_TTR['Analyst'].value_counts().reset_index()\n",
    "SLA_Met.columns = ['Analyst', 'Resolved Tkt']\n",
    "\n",
    "\n",
    "# Create 'TQR' dataframe\n",
    "new_data = data[['Analyst', 'P', 'C', 'R']]\n",
    "\n",
    "# Calculate average by Analyst\n",
    "avg_by_analyst = new_data.groupby('Analyst').mean()\n",
    "avg_by_analyst['TQR'] = avg_by_analyst.mean(axis=1)\n",
    "\n",
    "# Merge the DataFrames on 'Analyst' column to print all columns as a single table\n",
    "merged_table = pd.merge(ticket_counts, SLA_Met, on='Analyst', how='outer')\n",
    "merged_table['SLA %'] = merged_table['Resolved Tkt'] / merged_table['Closed Tickets']\n",
    "merged_table = pd.merge(merged_table, avg_by_analyst[['TQR']], on='Analyst', how='outer')\n",
    "\n",
    "merged_table.dropna(axis=0, inplace=True)\n",
    "\n",
    "print(merged_table)\n",
    "\n",
    "# file_path = \"merged_data.xlsx\"\n",
    "\n",
    "# # Save the DataFrame to an Excel file\n",
    "# merged_table.to_excel(file_path, index=False)\n",
    "\n",
    "# print(\"Data has been saved to\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create 'TQR' dataframe\n",
    "# new_data = data[['Analyst', 'P', 'C', 'R']]\n",
    "\n",
    "# # Calculate average by Analyst\n",
    "# avg_by_analyst = new_data.groupby('Analyst').mean()\n",
    "# avg_by_analyst['Average'] = (avg_by_analyst['P'] + avg_by_analyst['C'] + avg_by_analyst['R']) / 3\n",
    "\n",
    "# avg_by_analyst = avg_by_analyst[~avg_by_analyst['Average'].isnull()]\n",
    "\n",
    "# with pd.ExcelWriter('outputs.xlsx') as writer:  # doctest: +SKIP\n",
    "    \n",
    "#     data.to_excel(writer, sheet_name='Data', index=False)\n",
    "#     new_data.to_excel(writer, sheet_name='TQR', index=False)\n",
    "#     avg_by_analyst[['Average']].reset_index().to_excel(writer, sheet_name='Avg', index=False)\n",
    "\n",
    "\n",
    "# print(\"Excel file with three sheets has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file with three sheets, with 'Avg' sheet containing 'Analyst' and 'Average' columns (excluding rows with blank 'Average'), and borders for each cell has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "from openpyxl.styles import Border, Side\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Assuming 'data' DataFrame is defined elsewhere in your code\n",
    "\n",
    "# Create 'TQR' dataframe\n",
    "# new_data = data[['Analyst', 'P', 'C', 'R']]\n",
    "\n",
    "# # Calculate average by Analyst\n",
    "# avg_by_analyst = new_data.groupby('Analyst').mean()\n",
    "# avg_by_analyst['Average'] = ((avg_by_analyst['P'] + avg_by_analyst['C'] + avg_by_analyst['R']) / 3)  # Convert to percentage\n",
    "\n",
    "# # Filter rows where 'Average' is not NaN\n",
    "# avg_by_analyst = avg_by_analyst[~avg_by_analyst['Average'].isnull()]\n",
    "\n",
    "# Write to Excel file without index\n",
    "with pd.ExcelWriter('output.xlsx') as writer:  \n",
    "    data.to_excel(writer, sheet_name='Data', index=False)\n",
    "    # new_data.to_excel(writer, sheet_name='TQR', index=False)\n",
    "    # avg_by_analyst[['Average']].reset_index().to_excel(writer, sheet_name='Avg', index=False)  # Selecting only 'Analyst' and 'Average' columns\n",
    "    merged_table.to_excel(writer, sheet_name='Dashboard')\n",
    "\n",
    "# Load the workbook\n",
    "wb = load_workbook('output.xlsx')\n",
    "\n",
    "# Define border style\n",
    "border_style = Border(left=Side(style='thin'),\n",
    "                      right=Side(style='thin'),\n",
    "                      top=Side(style='thin'),\n",
    "                      bottom=Side(style='thin'))\n",
    "\n",
    "# Apply border to all cells in all sheets\n",
    "for sheet in wb.sheetnames:\n",
    "    ws = wb[sheet]\n",
    "    for row in ws.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.border = border_style\n",
    "\n",
    "# Set percentage format for 'Average' column in 'Avg' sheet\n",
    "ws_avg = wb['Dashboard']\n",
    "for row in ws_avg.iter_rows(min_row=2, max_row=ws_avg.max_row, min_col=6, max_col=7):\n",
    "    for cell in row:\n",
    "        cell.number_format = '0%'  # Set percentage format with two decimal places\n",
    "\n",
    "# Save the workbook\n",
    "wb.save('output.xlsx')\n",
    "\n",
    "print(\"Excel file with three sheets, with 'Avg' sheet containing 'Analyst' and 'Average' columns (excluding rows with blank 'Average'), and borders for each cell has been created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
